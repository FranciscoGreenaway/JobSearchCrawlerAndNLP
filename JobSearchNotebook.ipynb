{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Cisco\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "PATH = 'C:\\Program Files (x86)\\chromedriver.exe'\n",
    "driver = webdriver.Chrome(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def get_user_info():\n",
    "    # Prompting user for job title and zip-code\n",
    "    while True:\n",
    "        job_title = str(input(\"What job title are you searching for? (Don't enter digits or symbols)\"))\n",
    "        if all(i.isalpha() or i.isspace() for i in job_title):\n",
    "            break\n",
    "        else:\n",
    "            print(\"Please do not enter digits or symbols. \")\n",
    "\n",
    "    # Handling non-integer exceptions\n",
    "    while True:\n",
    "        try:\n",
    "            user_zip_code = int(input(\"What is your 5 digit zip code? \"))\n",
    "            if len(str(user_zip_code)) == 5:\n",
    "                break\n",
    "        except ValueError:\n",
    "            print(\"That was not a valid 5 digit zip code. Please try again. \")\n",
    "\n",
    "    get_url(job_title, user_zip_code)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def get_url(job_title, user_zip_code):\n",
    "    # Using user input to create url\n",
    "    cleaned_url = job_title.replace(\" \", \"+\")\n",
    "    url = \"https://www.indeed.com/jobs?q=\" + cleaned_url + \"&l=\" + str(user_zip_code)\n",
    "    driver.get(url)\n",
    "\n",
    "    # Give page time to load to see if pop up actually appears\n",
    "    time.sleep(3)\n",
    "\n",
    "    # Check if pop up box appears\n",
    "    try:\n",
    "        # Exits \"creating a account\" popup window\n",
    "        driver.find_element_by_xpath(\"//button[@class='popover-x-button-close icl-CloseButton']\").click()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    print(f\"Searching through {url} for results...\")\n",
    "\n",
    "    scrape()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def scrape():\n",
    "    page_info = []\n",
    "    main_info = []\n",
    "    job_website_links = []\n",
    "\n",
    "    '''\n",
    "    Alternative form of getting job text\n",
    "    main_content = driver.find_element_by_id('resultsCol')\n",
    "    # print(main_content.text)\n",
    "\n",
    "    time.sleep(5)\n",
    "\n",
    "    jobs = main_content.find_elements_by_class_name('resultContent')\n",
    "    time.sleep(5)\n",
    "\n",
    "    for job in jobs:\n",
    "        time.sleep(5)\n",
    "        print(job.text)\n",
    "        print(\"-----------------------\")\n",
    "    '''\n",
    "\n",
    "    main_content = driver.find_element_by_id('mosaic-provider-jobcards')\n",
    "    time.sleep(10)\n",
    "    jobs = main_content.find_elements_by_tag_name('a')\n",
    "    time.sleep(10)\n",
    "\n",
    "    # Looping through every 'a' tag within the main_content\n",
    "    for job in jobs:\n",
    "        # Getting correct href and printing it\n",
    "        #   there is several 'a' tags within the original 'a' tag.\n",
    "        correct_link = job.get_attribute('data-mobtk')\n",
    "        if correct_link is None:\n",
    "            continue\n",
    "        else:\n",
    "            href = job.get_attribute('href')\n",
    "            time.sleep(10)\n",
    "\n",
    "            # Put info into list\n",
    "            page_info.append(job.text + '\\n' +href)\n",
    "\n",
    "    # Looping through page_info to append the main info we want to a new list\n",
    "    for item in page_info:\n",
    "\n",
    "        if not item.startswith('new'):\n",
    "            [position_name, company_name, company_location, *_, link] = item.split('\\n')\n",
    "            main_info.append({'Position Title' : position_name, 'Company Name': company_name, 'Location': company_location, 'Link': link})\n",
    "        else:\n",
    "            [_, position_name, company_name, company_location, *_, link] = item.split('\\n')\n",
    "            main_info.append({'Position Title' : position_name, 'Company Name': company_name, 'Location': company_location, 'Link': link})\n",
    "\n",
    "        job_website_links.append(link)\n",
    "\n",
    "    create_dataframe(main_info)\n",
    "    analyzing_sites(job_website_links)\n",
    "\n",
    "    '''\n",
    "    Works but takes much longer\n",
    "\n",
    "    print(\"-------------------Job Titles--------------------\")\n",
    "    titles = driver.find_elements_by_tag_name(\"h2\")\n",
    "    for title in titles:\n",
    "        print(title.text)\n",
    "\n",
    "    time.sleep(5)\n",
    "\n",
    "    print(\"===================Job Locations====================\")\n",
    "    time.sleep(5)\n",
    "\n",
    "    company_location = driver.find_elements_by_class_name('companyLocation')\n",
    "    for location in company_location:\n",
    "        print(location.text)\n",
    "\n",
    "    time.sleep(5)\n",
    "    print(\"===================Company Names=====================\")\n",
    "    time.sleep(5)\n",
    "    company_name = driver.find_elements_by_class_name('companyName')\n",
    "    for company in company_name:\n",
    "        print(company.text)\n",
    "    '''\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def create_dataframe(main_info):\n",
    "    df = pd.DataFrame(main_info)\n",
    "    # creating a csv\n",
    "    file_name = 'first_page_jobs_list.csv'\n",
    "    df.to_csv(file_name)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def analyzing_sites(job_website_links):\n",
    "\n",
    "    STOP = stopwords.words(\"english\")\n",
    "\n",
    "    # writing to a file\n",
    "    with open('analysis.txt', 'w') as wf:\n",
    "\n",
    "        # looping through the href list\n",
    "        for item in job_website_links:\n",
    "            driver.get(item)\n",
    "\n",
    "            # getting job description of a site\n",
    "            job_description_text = driver.find_element_by_id('jobDescriptionText').text\n",
    "            time.sleep(10)\n",
    "\n",
    "            wf.write(job_description_text)\n",
    "            time.sleep(10)\n",
    "\n",
    "    with open('analysis.txt', 'r') as rf:\n",
    "        text = rf.read()\n",
    "        text_tokens = word_tokenize(text)\n",
    "\n",
    "        # creating bag of words\n",
    "        word_bag = [word.lower() for word in text_tokens if len(word) > 2 and word not in STOP]\n",
    "\n",
    "        # creating ngrams of different length\n",
    "        unigram = ngrams(word_bag, 1)\n",
    "        bigram = ngrams(word_bag, 2)\n",
    "        trigram = ngrams(word_bag, 3)\n",
    "        quadrigram = ngrams(word_bag, 4)\n",
    "\n",
    "    unigram_freq = collections.Counter(unigram)\n",
    "    bigram_freq = collections.Counter(bigram)\n",
    "    trigram_freq = collections.Counter(trigram)\n",
    "    quadrigram_freq = collections.Counter(quadrigram)\n",
    "\n",
    "\n",
    "    frequency(unigram_freq, bigram_freq, trigram_freq, quadrigram_freq)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def frequency(unigram_freq, bigram_freq, trigram_freq, quadrigram_freq):\n",
    "\n",
    "\n",
    "    for word, freq in unigram_freq.most_common(20):\n",
    "        print(word, \"appears\", freq, \"times\")\n",
    "    print()\n",
    "    for words, freq in bigram_freq.most_common(15):\n",
    "        print(words, \"appears\", freq, \"times\")\n",
    "    print()\n",
    "    for words, freq in trigram_freq.most_common(15):\n",
    "        print(words, \"appears\", freq, \"times\")\n",
    "    print()\n",
    "    for words, freq in quadrigram_freq.most_common(15):\n",
    "        print(words, \"appears\", freq, \"times\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "def ask_user():\n",
    "    interested = input(\"Are you interested in finding a job in your area? (yes/no)\")\n",
    "\n",
    "    if interested.lower().startswith(\"y\"):\n",
    "        get_user_info()\n",
    "    else:\n",
    "        print(\"Have A Great Day!\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Have A Great Day!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    ask_user()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}